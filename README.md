# Victory-Vision-AI
**NFL AI Game Prediction Model**

I built Victory Vision AI to predict weekly NFL game outcomes with a clean, transparent pipeline that is easy to run and easy to understand. This started as a school project, and I used online resources and open-source examples to navigate the AI side while applying my own football background to make sure the features reflect how teams actually play. This repository includes my original baseline and the improved version side by side so anyone can see the evolution, why I made certain changes, and how the final system works end to end.



**Table of Contents**

  - Project Goals
  - Repository Contents
  - Data Inputs
  - End-to-End Pipeline
    1. Ingestion and Merging
    2. Team Feature Engineering
    3. Training Matrix Construction
    4. Model Training and Calibration
    5. Prediction for Upcoming Games
    6. Display and Export
  - Design Decisions and Rationale
  - Current Handicaps and Restrictions
  - How to Run
    A. Run the Notebook
    B. Run the Script
  - Expected Columns and Schemas
  - Troubleshooting
  - Roadmap
  - Acknowledgments
  - License





**Project Goals**

  - Predict NFL win/loss outcomes on a weekly cadence with a model that is fast, stable, and easy to interpret.
  - Keep the code readable and consistent. Comments in the code use a neutral, third-person style.
  - Preserve the original baseline next to the improved version so readers can see what changed and why.
  - Avoid heavy external dependencies in the first phase by relying on reliable team-level features derived from historical data.





**Repository Contents**

I maintain both the improved and original versions, in notebook and script form.

VictoryVisionAI.ipynb
  - Improved end-to-end notebook: ingestion, features, calibrated logistic regression, out-of-fold thresholding, prediction, and optional CSV export.

victoryvisionai.py
  - Script version of the improved notebook, designed for weekly runs without manual interaction.

VictoryVisionAIOriginal2.ipynb
  - Original baseline notebook. Useful for comparison and to see why the improvements were made.

victoryvisionaioriginal2.py
  - Script version of the original baseline.

nfl_2024_new.csv
  - Play-by-play data for the 2024 season, Weeks 1 through 17.

nfl_2024_scores.csv
  - Final scores for the 2024 season.

upcoming_games_2025_week1.csv
  - Schedule for Week 1 of the 2025 season.

week1_predictions.csv
  - Output generated by the improved pipeline when the export step runs.

Note: I didn’t include a requirements.txt yet by choice. The minimal packages used are NumPy, pandas, and scikit-learn.





**Data Inputs**

The project uses three CSV files at the repository root by default. Paths can be changed near the top of the code.

1. nfl_2024_new.csv
Play-by-play rows including date, offense team, defense team, yards, touchdown flag, interception flag, fumble flag, incompletion flag, rush flag, and season year.

2. nfl_2024_scores.csv
One row per game with date, home team, visitor team, home points, visitor points, week number, and overtime flag.

3. upcoming_games_2025_week1.csv
Schedule for the forecast horizon; contains home and visitor teams and can include a week column.





**End-to-End Pipeline**

1. Ingestion and Merging
   - Load the 2024 play-by-play data and 2024 final scores.
   - Perform a two-pass merge to align play-by-play rows to the correct game.
     - Pass 1 aligns OffenseTeam vs DefenseTeam with Visitor vs Home.
     - Pass 2 flips that alignment to catch cases the first pass misses.
   - Fill the main columns from either pass and drop the temporary reverse columns.
   - Build the binary target HomeWon from final scores.

  This double merge avoids silent mismatches when “home/visitor” do not line up with “offense/defense” in raw rows.

2. Team Feature Engineering
   
  All features are computed at the team level; they are later differenced at the game level.
  - Scoring and prevention
    - Average points scored and allowed by combining home and away splits.
    - Win rate across home and away.
  - Defensive tendencies
    - Conceded plays rate (a conceded play is a touchdown or any non-turnover play).
    - Forced turnover rate (interceptions or fumbles).
  - Offensive efficiency
    - Average yards per play.
    - Average yards per game normalized at the season level.
    - Pass completion rate derived from incompletion flags.
    - Touchdowns per game normalized at the season level.
    - Rush success as average yards on rush plays.
  - Defensive efficiency mirrors
    - Yards allowed per play and per game, season normalized.
    - Pass completion allowed rate from incompletion flags.
    - Touchdowns allowed per game.
    - Rush success allowed rate.

  All features are merged into a single team-level feature table keyed by team name.

3. Training Matrix Construction
  - Merge team features onto each historical game twice, once for the home team and once for the visitor team.
  - Construct game-level inputs by taking home minus visitor for each team feature.
  - This produces Diff_<feature> columns (e.g., Diff_AvgPointsScored).
  - Select all Diff_ columns as inputs X and use HomeWon as labels y.
  - Run sanity checks for shape, index alignment, missing values, numeric dtypes, and label distribution.

4. Model Training and Calibration
  The improved model uses calibrated logistic regression with cross-validated tuning and out-of-fold (OOF) threshold selection.

  - Clean the training matrix by replacing infinite values, filling missing values, and enforcing numeric dtypes.
  - Build a Pipeline with StandardScaler and LogisticRegression. Use class_weight='balanced' for stability if classes are not perfectly balanced.
  - Run randomized search over the regularization strength. A DEBUG_FAST flag reduces search size and folds for quick iteration; turning it off expands the search and increases folds for the weekly run.
  - Calibrate probabilities using CalibratedClassifierCV with sigmoid calibration on cross-validation folds.
  - Compute an OOF optimal threshold by sweeping from 0.30 to 0.70 and choosing the value that maximizes accuracy on OOF probabilities.
  - Clamp the display threshold to at least 0.50 for the final table to avoid showing a predicted winner with a displayed probability under 0.50. The OOF optimal threshold is still retained and printed for reference.

Why calibration and OOF thresholding matter:
 - Calibration improves probability quality compared to raw model outputs.
 - OOF thresholding uses validation folds to find a more robust decision cutoff than a fixed 0.50. The clamp only affects the display.

5. Prediction for Upcoming Games
  - Merge team features onto the upcoming schedule for both home and visitor teams.
  - Build game-level inputs by differencing home minus visitor features in the same order as training.
  - Sanitize inputs, reorder columns to match training, and generate calibrated probabilities.
  - Apply the clamped display threshold to label the predicted winner.

6. Display and Export
  - Sort predictions by home win probability.
  - Optionally round probabilities for display.
  - Optionally write the full prediction table to week1_predictions.csv for downstream use.





**Design Decisions and Rationale**

  - Team-level features are stable, low-noise, and easy to compute from historical data that I control. This keeps data quality high without external APIs.
  - Home minus visitor differences create game-level signals without leaking information. This mirrors how matchups are discussed in real football analysis.
  - Logistic regression with calibration is fast and interpretable. It plays well with tabular features and runs quickly for weekly cadence work.
  - Cross-validation with randomized search tunes regularization without overfitting to a single split.
  - OOF thresholding optimizes the decision cutoff on validation folds. A clamp at 0.50 keeps the presentation intuitive.
  - A DEBUG_FAST flag makes iteration fast; turning it off expands the search and folds for a fuller weekly run.





**Current Handicaps and Restrictions**

These are the most important gaps that limit accuracy. They are intentionally out of scope for this first phase and will be addressed iteratively.

Injuries and roster availability
  - The model does not ingest live injury reports, practice participation, game-time decisions, or late scratches.
  - The impact of injuries varies by position and player quality (e.g., a starting QB vs. a rotational defender).
  - Adding this would require reliable feeds and a robust weighting scheme.

Weather and field conditions
  - The model does not include wind, temperature, precipitation, or field surface effects.
  - Weather can affect pass rate, kick distance, and turnover rates.
  - Mapping raw weather values to win probability takes careful study and can vary by team.

Market information and priors
  - The model does not use closing moneyline, spreads, or totals.
  - Market numbers are powerful priors but require an external data source and care to avoid leakage.

Schedule context and travel
  - The model does not include short-week flags, rest days, travel distance, time-zone shifts, or primetime context.
  - These factors can change performance on the margins, especially on short rest.

Recency weighting
  - The model uses full-season team summaries.
  - Many teams evolve within a season; recent-form features (e.g., exponentially weighted averages over the last 3–5 games) can help.

Roster changes and draft picks
  - The model does not attempt to quantify offseason changes or rookies.
  - This is difficult to model without long-term player data and context.

Naming and data quality
  - Team name mismatches, missing rows, or changes in CSV schema can cause silent issues if not handled.
  - The code includes basic checks, but external changes can still introduce noise.

I plan to improve these areas over time as I add data sources and define weighting strategies that make sense on the field and in the data.





**How to Run**

A. Run the Notebook
  1. Open “VictoryVisionAI.ipynb”.
  2. Verify the file paths near the top for nfl_2024_new.csv, nfl_2024_scores.csv, and upcoming_games_2025_week1.csv.
  3. Set DEBUG_FAST = True for quick iteration or set it to False for a fuller cross-validation run.
  4. Run all cells from top to bottom.
  5. The display will show predictions. The export step will write week1_predictions.csv by default.

B. Run the Script
  1. Make sure Python with NumPy, pandas, and scikit-learn is available.
  2. Verify that the three CSV inputs are in the repository root.
  3. Run the script from a terminal:
     - python victoryvisionai.py
  4. The script will print predictions to the console and save an output CSV if the export is enabled inside the script.





**Expected Columns and Schemas**

This is a summary of the columns the code expects to find. Extra columns are ignored. If these are missing or renamed, errors will occur.

nfl_2024_new.csv (play-by-play)
   - Date
   - OffenseTeam
   - DefenseTeam
   - Yards
   - IsTouchdown
   - IsInterception
   - IsFumble
   - IsIncomplete
   - IsRush
   - SeasonYear

nfl_2024_scores.csv (final scores)
  - Date
  - Week
  - Visitor
  - VisitorScore
  - Home
  - HomeScore
  - OT

upcoming_games_2025_week1.csv (schedule)
  - Home
  - Visitor
  - Week (optional but supported)

If your data uses different names, update the merge keys and column references in the code.





**Troubleshooting**

Mismatched or missing team names
  - If a team name is spelled differently between files, merges can fail or produce missing features.
  - Standardize names across CSVs or add a small mapping layer.

NaN or infinite values
  - The code replaces infinite values and fills NaN with zeros in training and prediction matrices.
  - If the counts are high, it indicates deeper data issues that should be addressed at the source.

Probabilities look too confident or too flat
  - Confirm that training and prediction features use the same Diff_ columns in the same order.
  - Make sure the calibration and thresholding steps have run.
  - Check that DEBUG_FAST is set appropriately for your run.

Display shows a predicted winner under 0.50 probability
  - The code clamps the display threshold to 0.50 to keep the table intuitive.
  - The out-of-fold optimal threshold can be lower than 0.50. The clamp only affects the display.





**Roadmap**

  - Add recent-form features such as exponentially weighted averages over the last 3–5 games.
  - Add schedule context features such as short-week flags, rest days, travel distance, and time-zone shifts.
  - Add market priors such as closing moneyline or spread in a way that avoids leakage.
  - Add high-impact injury signals starting with quarterback availability.
  - Explore weather features for wind, temperature, and precipitation effects.
  - Consider an Elastic Net logistic model for sparse signal or a tree model after feature upgrades.
  - Build a small data validation layer to standardize team names and schemas before merges.





**Acknowledgments**

This started as a school project. I used online resources and open-source examples to learn best practices for tabular modeling, calibration, and cross-validation. I applied my football understanding to define features that reflect how teams score, defend, and control games. Thanks to the authors of the open-source tools that make this work practical.





**License**

No license is provided yet. All rights reserved by default. If you plan to use this code beyond personal or educational purposes, contact me first.
