{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "fKv43ILy_bGu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m4JVPto6fNw"
      },
      "outputs": [],
      "source": [
        "# Imports and basic configuration\n",
        "\n",
        "# Core utilities\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Numerics and dataframes\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Modeling utilities\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Set global random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Configure pandas display for better readability in notebooks\n",
        "pd.set_option('display.width', 140)\n",
        "pd.set_option('display.max_columns', 120)\n",
        "\n",
        "# Suppress unnecessary warnings during execution\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define base directory for data files\n",
        "DATA_DIR = \".\"\n",
        "\n",
        "# Define full paths for key data files\n",
        "PBP_FILE = os.path.join(DATA_DIR, \"nfl_2024_new.csv\")\n",
        "SCORES_FILE = os.path.join(DATA_DIR, \"nfl_2024_scores.csv\")\n",
        "UPCOMING_FILE = os.path.join(DATA_DIR, \"upcoming_games_2025_week1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping/Merging Data"
      ],
      "metadata": {
        "id": "87o4gA7s_ko5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data ingestion and merging\n",
        "\n",
        "# Load 2024 play-by-play data (Weeks 1–17 only)\n",
        "pbp_df = pd.read_csv(PBP_FILE)\n",
        "\n",
        "# Load 2024 final scores for all games\n",
        "scores_df = pd.read_csv(SCORES_FILE)\n",
        "\n",
        "# Merge 1: Attempt to join by matching Offense vs. Defense to Visitor vs. Home\n",
        "merged = pbp_df.merge(\n",
        "    scores_df,\n",
        "    left_on=['Date', 'OffenseTeam', 'DefenseTeam'],\n",
        "    right_on=['Date', 'Visitor', 'Home'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge 2: Reverse the roles to catch games where Home/Visitor are flipped\n",
        "merged = merged.merge(\n",
        "    scores_df,\n",
        "    left_on=['Date', 'OffenseTeam', 'DefenseTeam'],\n",
        "    right_on=['Date', 'Home', 'Visitor'],\n",
        "    how='left',\n",
        "    suffixes=('', '_reverse')\n",
        ")\n",
        "\n",
        "# Fill missing columns using reverse match when needed\n",
        "for col in ['Week', 'Visitor', 'VisitorScore', 'Home', 'HomeScore', 'OT']:\n",
        "    merged[col] = merged[col].combine_first(merged[f\"{col}_reverse\"])\n",
        "\n",
        "# Drop the redundant reverse columns\n",
        "merged.drop(columns=[f\"{col}_reverse\" for col in ['Week', 'Visitor', 'VisitorScore', 'Home', 'HomeScore', 'OT']], inplace=True)\n",
        "\n",
        "# Add binary target column: 1 if Home team won, 0 otherwise\n",
        "merged['HomeWon'] = merged['HomeScore'] > merged['VisitorScore']\n",
        "\n",
        "# Preview merged dataset\n",
        "merged[['Date', 'Home', 'Visitor', 'HomeScore', 'VisitorScore', 'HomeWon']].head(50)"
      ],
      "metadata": {
        "id": "LrJ3F7Kz_lIg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team Feature Extraction"
      ],
      "metadata": {
        "id": "8fDWgYsD_lda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: basic scoring and win rate metrics\n",
        "\n",
        "# Load schedule for upcoming games (Week 1 of 2025 season)\n",
        "upcoming_games = pd.read_csv(UPCOMING_FILE)\n",
        "\n",
        "# Preview the upcoming schedule to verify the structure\n",
        "print(upcoming_games.head(16))\n",
        "\n",
        "# --- Average Points Scored ---\n",
        "\n",
        "# Calculate average points scored at home and away\n",
        "avg_scored_home = merged['HomeScore'].groupby(merged['Home']).mean()\n",
        "avg_scored_away = merged['VisitorScore'].groupby(merged['Visitor']).mean()\n",
        "\n",
        "# Combine to get total average points scored per team\n",
        "avg_points_scored = (avg_scored_home + avg_scored_away) / 2\n",
        "\n",
        "# --- Average Points Allowed ---\n",
        "\n",
        "# Calculate average points allowed at home and away\n",
        "avg_allowed_home = merged['VisitorScore'].groupby(merged['Home']).mean()\n",
        "avg_allowed_away = merged['HomeScore'].groupby(merged['Visitor']).mean()\n",
        "\n",
        "# Combine to get total average points allowed per team\n",
        "avg_points_allowed = (avg_allowed_home + avg_allowed_away) / 2\n",
        "\n",
        "# --- Win Rate ---\n",
        "\n",
        "# Count wins as home and away\n",
        "home_wins = merged.groupby('Home')['HomeWon'].sum()\n",
        "away_wins = merged.groupby('Visitor')['HomeWon'].apply(lambda x: len(x) - x.sum())\n",
        "\n",
        "# Count total games played as home and away\n",
        "home_games = merged['Home'].value_counts()\n",
        "away_games = merged['Visitor'].value_counts()\n",
        "\n",
        "# Total wins and games played\n",
        "total_wins = home_wins + away_wins\n",
        "total_games = home_games + away_games\n",
        "\n",
        "# Calculate overall win rate\n",
        "win_rate = total_wins / total_games\n",
        "\n",
        "# --- Assemble team-level features ---\n",
        "\n",
        "# Combine all features into one DataFrame\n",
        "team_features = pd.DataFrame({\n",
        "    'AvgPointsScored': avg_points_scored,\n",
        "    'AvgPointsAllowed': avg_points_allowed,\n",
        "    'WinRate': win_rate\n",
        "})\n",
        "\n",
        "# Reset index and name the index column explicitly\n",
        "team_features.reset_index(names='Team', inplace=True)\n",
        "\n",
        "# Preview the engineered features\n",
        "team_features.head(32)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dkK9soYk_l3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: defensive metrics (conceded plays and turnovers)\n",
        "\n",
        "# --- Conceded Plays ---\n",
        "\n",
        "# Define a successful offensive play as either a touchdown or a non-turnover play\n",
        "merged['SuccessfulPlay'] = merged['IsTouchdown'] | (~merged['IsInterception'] & ~merged['IsFumble'])\n",
        "\n",
        "# Calculate average rate of successful plays conceded at home and as a visitor\n",
        "avg_conceded_home = merged.groupby('Home')['SuccessfulPlay'].mean()\n",
        "avg_conceded_away = merged.groupby('Visitor')['SuccessfulPlay'].mean()\n",
        "\n",
        "# Combine to get overall conceded play rate per team\n",
        "avg_conceded_plays = (avg_conceded_home + avg_conceded_away) / 2\n",
        "\n",
        "# --- Forced Turnovers ---\n",
        "\n",
        "# Define a turnover as either an interception or a fumble\n",
        "merged['Turnover'] = merged['IsInterception'] | merged['IsFumble']\n",
        "\n",
        "# Calculate average forced turnovers at home and as a visitor\n",
        "avg_turnovers_home = merged.groupby('Home')['Turnover'].mean()\n",
        "avg_turnovers_away = merged.groupby('Visitor')['Turnover'].mean()\n",
        "\n",
        "# Combine to get overall forced turnover rate per team\n",
        "avg_forced_turnovers = (avg_turnovers_home + avg_turnovers_away) / 2\n",
        "\n",
        "# --- Merge Defensive Features ---\n",
        "\n",
        "# Create defensive metrics dataframe\n",
        "team_features_def = pd.DataFrame({\n",
        "    'Team': team_features['Team'],\n",
        "    'AvgPointsDefended': team_features['AvgPointsAllowed'],  # Already calculated earlier\n",
        "    'AvgConcededPlays': avg_conceded_plays.values,\n",
        "    'AvgForcedTurnovers': avg_forced_turnovers.values\n",
        "})\n",
        "\n",
        "# Join defensive features into existing feature set\n",
        "team_features_combined = team_features.merge(team_features_def, on='Team', how='left')\n",
        "\n",
        "# Preview combined features\n",
        "team_features_combined.head(32)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gf9OcSPq44hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: additional offensive metrics\n",
        "\n",
        "# --- Average Yards Per Play ---\n",
        "\n",
        "# Calculate mean yards gained per play at home and away\n",
        "avg_yards_home = merged.groupby('Home')['Yards'].mean()\n",
        "avg_yards_away = merged.groupby('Visitor')['Yards'].mean()\n",
        "\n",
        "# Combine for team-wide average\n",
        "avg_yards_per_play = (avg_yards_home + avg_yards_away) / 2\n",
        "\n",
        "# --- Average Yards Per Game ---\n",
        "\n",
        "# Sum total yards per team per season and divide by number of games played\n",
        "total_yards_home = merged.groupby(['SeasonYear', 'Home'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Home']).size()\n",
        "total_yards_away = merged.groupby(['SeasonYear', 'Visitor'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()\n",
        "\n",
        "# Combine to get team-wide season average\n",
        "avg_yards_per_game = (total_yards_home + total_yards_away).groupby(level=1).mean()\n",
        "\n",
        "# --- Pass Completion Rate ---\n",
        "\n",
        "# Completion rate = 1 - incompletion rate\n",
        "pass_comp_home = merged.groupby('Home')['IsIncomplete'].mean().apply(lambda x: 1 - x)\n",
        "pass_comp_away = merged.groupby('Visitor')['IsIncomplete'].mean().apply(lambda x: 1 - x)\n",
        "\n",
        "# Combine to get overall pass completion rate\n",
        "avg_pass_completion = (pass_comp_home + pass_comp_away) / 2\n",
        "\n",
        "# --- Touchdowns Per Game ---\n",
        "\n",
        "# Touchdowns per game = total TDs divided by games played (per season)\n",
        "tds_home = merged.groupby(['SeasonYear', 'Home'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Home']).size()\n",
        "tds_away = merged.groupby(['SeasonYear', 'Visitor'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()\n",
        "\n",
        "# Combine for average TDs per game per team\n",
        "avg_td_per_game = (tds_home + tds_away).groupby(level=1).mean()\n",
        "\n",
        "# --- Rush Success Rate ---\n",
        "\n",
        "# Rush success = average yards per rush\n",
        "rush_success_home = merged[merged['IsRush'] == 1].groupby('Home')['Yards'].mean()\n",
        "rush_success_away = merged[merged['IsRush'] == 1].groupby('Visitor')['Yards'].mean()\n",
        "\n",
        "# Combine for team-wide average\n",
        "avg_rush_success = (rush_success_home + rush_success_away) / 2\n",
        "\n",
        "# --- Combine and Merge Offensive Features ---\n",
        "\n",
        "# Create DataFrame of offensive metrics\n",
        "offensive_features = pd.DataFrame({\n",
        "    'Team': team_features_combined['Team'],\n",
        "    'AvgYardsPerPlay': avg_yards_per_play.values,\n",
        "    'AvgYardsPerGame': avg_yards_per_game.values,\n",
        "    'AvgPassCompletionRate': avg_pass_completion.values,\n",
        "    'AvgTouchdownsPerGame': avg_td_per_game.values,\n",
        "    'AvgRushSuccessRate': avg_rush_success.values\n",
        "})\n",
        "\n",
        "# Merge into existing team feature set\n",
        "team_features_expanded = team_features_combined.merge(offensive_features, on='Team')\n",
        "\n",
        "# Preview final offensive features\n",
        "team_features_expanded.head(32)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "REtOTbdO5I2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: additional defensive metrics\n",
        "\n",
        "# --- Yards Allowed Per Play ---\n",
        "\n",
        "# Calculate average yards allowed per play at home and away\n",
        "yards_allowed_home = merged.groupby('Home')['Yards'].mean()\n",
        "yards_allowed_away = merged.groupby('Visitor')['Yards'].mean()\n",
        "\n",
        "# Combine to get total average yards allowed per team\n",
        "avg_yards_allowed = (yards_allowed_home + yards_allowed_away) / 2\n",
        "\n",
        "# --- Total Yards Allowed Per Game ---\n",
        "\n",
        "# Sum total yards allowed per season and divide by number of games\n",
        "total_yards_home = merged.groupby(['SeasonYear', 'Home'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Home']).size()\n",
        "total_yards_away = merged.groupby(['SeasonYear', 'Visitor'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()\n",
        "\n",
        "# Combine and average over both sides\n",
        "avg_yards_allowed_per_game = (total_yards_home + total_yards_away).groupby(level=1).mean()\n",
        "\n",
        "# --- Pass Completion Allowed Rate ---\n",
        "\n",
        "# Completion rate allowed = 1 - incompletion rate\n",
        "comp_allowed_home = merged.groupby('Home')['IsIncomplete'].mean().apply(lambda x: 1 - x)\n",
        "comp_allowed_away = merged.groupby('Visitor')['IsIncomplete'].mean().apply(lambda x: 1 - x)\n",
        "\n",
        "# Combine for overall allowed completion rate\n",
        "avg_pass_completion_allowed = (comp_allowed_home + comp_allowed_away) / 2\n",
        "\n",
        "# --- Touchdowns Allowed Per Game ---\n",
        "\n",
        "# Calculate touchdowns allowed per game from both sides\n",
        "tds_allowed_home = merged.groupby(['SeasonYear', 'Home'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Home']).size()\n",
        "tds_allowed_away = merged.groupby(['SeasonYear', 'Visitor'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()\n",
        "\n",
        "# Combine and average\n",
        "avg_tds_allowed_per_game = (tds_allowed_home + tds_allowed_away).groupby(level=1).mean()\n",
        "\n",
        "# --- Rush Success Allowed Rate ---\n",
        "\n",
        "# Calculate average yards per rush allowed at home and away\n",
        "rush_allowed_home = merged[merged['IsRush'] == 1].groupby('Home')['Yards'].mean()\n",
        "rush_allowed_away = merged[merged['IsRush'] == 1].groupby('Visitor')['Yards'].mean()\n",
        "\n",
        "# Combine for overall rush success rate allowed\n",
        "avg_rush_success_allowed = (rush_allowed_home + rush_allowed_away) / 2\n",
        "\n",
        "# --- Combine and Merge Defensive Features ---\n",
        "\n",
        "# Create DataFrame of defensive metrics\n",
        "defensive_features = pd.DataFrame({\n",
        "    'Team': team_features_expanded['Team'],\n",
        "    'AvgYardsAllowedPerPlay': avg_yards_allowed.values,\n",
        "    'AvgYardsAllowedPerGame': avg_yards_allowed_per_game.values,\n",
        "    'AvgPassCompletionAllowedRate': avg_pass_completion_allowed.values,\n",
        "    'AvgTouchdownsAllowedPerGame': avg_tds_allowed_per_game.values,\n",
        "    'AvgRushSuccessAllowedRate': avg_rush_success_allowed.values\n",
        "})\n",
        "\n",
        "# Merge with the previous feature set\n",
        "team_features_complete = team_features_expanded.merge(defensive_features, on='Team')\n",
        "\n",
        "# Preview the completed team feature dataset\n",
        "team_features_complete.head(32)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S_m7vn2h5QOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Game-level feature encoding for upcoming Week 1 matchups\n",
        "\n",
        "# Reload upcoming games (redundant in Colab, but ensures fresh read if needed)\n",
        "upcoming_games = pd.read_csv(UPCOMING_FILE)\n",
        "\n",
        "# Merge home team features\n",
        "upcoming_merged = upcoming_games.merge(\n",
        "    team_features_complete,\n",
        "    left_on='Home',\n",
        "    right_on='Team',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge visitor team features and suffix columns appropriately\n",
        "upcoming_merged = upcoming_merged.merge(\n",
        "    team_features_complete,\n",
        "    left_on='Visitor',\n",
        "    right_on='Team',\n",
        "    how='left',\n",
        "    suffixes=('_Home', '_Visitor')\n",
        ")\n",
        "\n",
        "# Preview encoded game matrix\n",
        "upcoming_merged.head(16)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-TJ0jaCq5XRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Training Preparation"
      ],
      "metadata": {
        "id": "dIENpvWPCClg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set construction: join game data with team features and build home-vs-visitor deltas\n",
        "\n",
        "# Merge team features for the home side\n",
        "training_encoded_home = merged.merge(\n",
        "    team_features_complete,\n",
        "    left_on='Home',\n",
        "    right_on='Team',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge team features for the visitor side (suffixes disambiguate feature columns)\n",
        "training_encoded_both = training_encoded_home.merge(\n",
        "    team_features_complete,\n",
        "    left_on='Visitor',\n",
        "    right_on='Team',\n",
        "    how='left',\n",
        "    suffixes=('_Home', '_Visitor')\n",
        ")\n",
        "\n",
        "# List the team-level feature names to difference (explicit for reproducibility)\n",
        "diff_source_cols = [\n",
        "    'AvgPointsScored', 'AvgPointsAllowed', 'WinRate',\n",
        "    'AvgPointsDefended', 'AvgConcededPlays', 'AvgForcedTurnovers',\n",
        "    'AvgYardsPerPlay', 'AvgYardsPerGame', 'AvgPassCompletionRate',\n",
        "    'AvgTouchdownsPerGame', 'AvgRushSuccessRate',\n",
        "    'AvgYardsAllowedPerPlay', 'AvgYardsAllowedPerGame',\n",
        "    'AvgPassCompletionAllowedRate', 'AvgTouchdownsAllowedPerGame',\n",
        "    'AvgRushSuccessAllowedRate'\n",
        "]\n",
        "\n",
        "# Create home-minus-visitor differences for each feature\n",
        "for col in diff_source_cols:\n",
        "    training_encoded_both[f'Diff_{col}'] = (\n",
        "        training_encoded_both[f'{col}_Home'] - training_encoded_both[f'{col}_Visitor']\n",
        "    )\n",
        "\n",
        "# Select model inputs (all Diff_ columns) and the target (home team win flag)\n",
        "training_data = training_encoded_both[[c for c in training_encoded_both.columns if c.startswith('Diff_')]]\n",
        "training_labels = training_encoded_both['HomeWon']\n",
        "\n",
        "# Preview a sample of the finalized training matrix\n",
        "training_data.head(50)"
      ],
      "metadata": {
        "id": "fevaFPKw53_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity checks: verify training matrix and labels before modeling\n",
        "\n",
        "# Basic shapes\n",
        "print(\"training_data shape:\", training_data.shape)\n",
        "print(\"training_labels shape:\", training_labels.shape)\n",
        "\n",
        "# Index alignment (ensures each row of X maps to the same row of y)\n",
        "aligned = training_data.index.equals(training_labels.index)\n",
        "print(\"Index aligned:\", aligned)\n",
        "\n",
        "# Missing values\n",
        "total_feature_nas = int(training_data.isna().sum().sum())\n",
        "label_nas = int(training_labels.isna().sum())\n",
        "print(\"Total missing values in training_data:\", total_feature_nas)\n",
        "print(\"Missing labels:\", label_nas)\n",
        "\n",
        "# Type check: ensure all features are numeric\n",
        "non_numeric_cols = training_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "print(\"Non-numeric feature columns:\", non_numeric_cols if non_numeric_cols else \"None\")\n",
        "\n",
        "# Label distribution (helps catch class imbalance issues)\n",
        "print(\"\\nLabel distribution (HomeWon):\")\n",
        "print(training_labels.value_counts(dropna=False))\n",
        "\n",
        "# Preview: show a small sample of the feature matrix\n",
        "print(\"\\nFeature columns (first 10):\", list(training_data.columns[:10]))\n",
        "training_data.head(10)"
      ],
      "metadata": {
        "id": "S1-24Lnr57cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Model Training"
      ],
      "metadata": {
        "id": "E9pJwojXmdJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AI model training: calibrated logistic regression with optimal threshold selection\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.base import clone\n",
        "import numpy as np\n",
        "\n",
        "# Debug flag for reduced search space and faster runtime during development\n",
        "DEBUG_FAST = True  # set to False for full weekly run\n",
        "\n",
        "# Sanitize training matrix to remove NaNs and infinite values\n",
        "X_train = training_data.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(float)\n",
        "y_train = training_labels.astype(int)\n",
        "\n",
        "# Define pipeline: scaling + logistic regression\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        solver='lbfgs',\n",
        "        class_weight='balanced',\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Define parameter grid (compact in debug, wider for full run)\n",
        "if DEBUG_FAST:\n",
        "    param_dist = {\n",
        "        'model__C': np.logspace(-2, 1, 6),   # 0.01 → 10\n",
        "        'model__penalty': ['l2'],\n",
        "    }\n",
        "    n_iter = 8\n",
        "    n_splits = 5\n",
        "else:\n",
        "    param_dist = {\n",
        "        'model__C': np.logspace(-3, 2, 10),  # 0.001 → 100\n",
        "        'model__penalty': ['l2'],\n",
        "    }\n",
        "    n_iter = 20\n",
        "    n_splits = 10\n",
        "\n",
        "# Define cross-validation strategy\n",
        "cv_strategy = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# Randomized search for accuracy\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=n_iter,\n",
        "    scoring=make_scorer(accuracy_score),\n",
        "    cv=cv_strategy,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Fit randomized search on the training matrix\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve best pipeline\n",
        "best_pipeline = random_search.best_estimator_\n",
        "\n",
        "# Calibrate probabilities for improved reliability\n",
        "calibrated_model = CalibratedClassifierCV(\n",
        "    estimator=best_pipeline,\n",
        "    method='sigmoid',\n",
        "    cv=cv_strategy\n",
        ")\n",
        "calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best CV Accuracy (search): {random_search.best_score_:.4f}\")\n",
        "print(f\"Chosen Parameters: {random_search.best_params_}\")\n",
        "\n",
        "# Function to compute optimal probability threshold using out-of-fold predictions\n",
        "def find_optimal_threshold_oof(estimator, X, y, cv):\n",
        "    oof_proba = np.zeros(len(y), dtype=float)\n",
        "    for train_idx, valid_idx in cv.split(X, y):\n",
        "        fold_est = clone(estimator)\n",
        "        fold_est.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
        "        oof_proba[valid_idx] = fold_est.predict_proba(X.iloc[valid_idx])[:, 1]\n",
        "\n",
        "    thresholds = np.linspace(0.30, 0.70, 401)\n",
        "    best_thr, best_acc = 0.5, -1.0\n",
        "    y_true = y.values\n",
        "    for thr in thresholds:\n",
        "        preds = (oof_proba >= thr).astype(int)\n",
        "        acc = (preds == y_true).mean()\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_thr = thr\n",
        "    return best_thr, best_acc\n",
        "\n",
        "# Compute optimal threshold\n",
        "OPTIMAL_THRESHOLD, OOF_ACC = find_optimal_threshold_oof(\n",
        "    estimator=calibrated_model,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    cv=cv_strategy\n",
        ")\n",
        "\n",
        "print(f\"Optimal OOF threshold: {OPTIMAL_THRESHOLD:.3f} (OOF accuracy at threshold: {OOF_ACC:.4f})\")\n",
        "\n",
        "# Persist references for prediction\n",
        "final_model = calibrated_model\n",
        "best_threshold = OPTIMAL_THRESHOLD\n",
        "decision_threshold = max(0.50, best_threshold)   # clamp display threshold to avoid sub-0.50 winners\n",
        "feature_order_ = X_train.columns                  # capture feature order for alignment at inference"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0dk2tF3cAQS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upcoming Game Predictions"
      ],
      "metadata": {
        "id": "lGFsPyN6mqDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction preparation: construct diffs for upcoming games and generate probabilities\n",
        "\n",
        "# Create a copy to avoid mutating the base data\n",
        "prediction_results = upcoming_merged.copy()\n",
        "\n",
        "# Define feature columns used during training\n",
        "feature_cols = [f\"Diff_{c}\" for c in diff_source_cols]\n",
        "\n",
        "# Create home-minus-visitor differences for each feature\n",
        "for col in diff_source_cols:\n",
        "    prediction_results[f'Diff_{col}'] = prediction_results[f'{col}_Home'] - prediction_results[f'{col}_Visitor']\n",
        "\n",
        "# Prepare model input matrix\n",
        "upcoming_X = prediction_results[feature_cols].copy()\n",
        "\n",
        "# Sanitize prediction matrix to remove NaNs and infinite values\n",
        "upcoming_X = upcoming_X.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(float)\n",
        "\n",
        "# Align feature order to match training data\n",
        "upcoming_X = upcoming_X.reindex(columns=feature_order_, fill_value=0.0)\n",
        "\n",
        "# Generate calibrated probabilities\n",
        "predicted_proba = final_model.predict_proba(upcoming_X)[:, 1]\n",
        "\n",
        "# Store probabilities and predicted winners (uses clamped decision_threshold for display)\n",
        "prediction_results['Home Win Probability'] = predicted_proba\n",
        "prediction_results['Predicted Winner'] = np.where(\n",
        "    prediction_results['Home Win Probability'] >= decision_threshold,\n",
        "    prediction_results['Home'],\n",
        "    prediction_results['Visitor']\n",
        ")"
      ],
      "metadata": {
        "id": "fmotwrZim-b_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display predictions\n",
        "\n",
        "# Select display columns\n",
        "display_cols = ['Home', 'Visitor', 'Home Win Probability', 'Predicted Winner']\n",
        "if 'Week' in prediction_results.columns:\n",
        "    display_cols = ['Week'] + display_cols\n",
        "\n",
        "# Sort by win probability in descending order\n",
        "upcoming_predictions = prediction_results[display_cols].sort_values(\n",
        "    by='Home Win Probability', ascending=False\n",
        ")\n",
        "\n",
        "# Show final prediction table\n",
        "upcoming_predictions"
      ],
      "metadata": {
        "id": "AqbPAD7Y-Asc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}