# -*- coding: utf-8 -*-
"""VictoryVisionAIOriginal2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xqzDfs_5VAVef-5w48xTYxqN-xp_-DNU

Importing Libraries
"""

# Imports and basic configuration

# Core utilities
import os
import random
import warnings

# Numerics and dataframes
import numpy as np
import pandas as pd

# Modeling utilities
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# Set global random seed for reproducibility
RANDOM_STATE = 42
random.seed(RANDOM_STATE)
np.random.seed(RANDOM_STATE)

# Configure pandas display for better readability in notebooks
pd.set_option('display.width', 140)
pd.set_option('display.max_columns', 120)

# Suppress unnecessary warnings during execution
warnings.filterwarnings('ignore')

# Define base directory for data files
DATA_DIR = "."

# Define full paths for key data files
PBP_FILE = os.path.join(DATA_DIR, "nfl_2024_new.csv")
SCORES_FILE = os.path.join(DATA_DIR, "nfl_2024_scores.csv")
UPCOMING_FILE = os.path.join(DATA_DIR, "upcoming_games_2025_week1.csv")

"""Scraping/Merging Data"""

# Data ingestion and merging

# Load 2024 play-by-play data (Weeks 1â€“17 only)
pbp_df = pd.read_csv(PBP_FILE)

# Load 2024 final scores for all games
scores_df = pd.read_csv(SCORES_FILE)

# Merge 1: Attempt to join by matching Offense vs. Defense to Visitor vs. Home
merged = pbp_df.merge(
    scores_df,
    left_on=['Date', 'OffenseTeam', 'DefenseTeam'],
    right_on=['Date', 'Visitor', 'Home'],
    how='left'
)

# Merge 2: Reverse the roles to catch games where Home/Visitor are flipped
merged = merged.merge(
    scores_df,
    left_on=['Date', 'OffenseTeam', 'DefenseTeam'],
    right_on=['Date', 'Home', 'Visitor'],
    how='left',
    suffixes=('', '_reverse')
)

# Fill missing columns using reverse match when needed
for col in ['Week', 'Visitor', 'VisitorScore', 'Home', 'HomeScore', 'OT']:
    merged[col] = merged[col].combine_first(merged[f"{col}_reverse"])

# Drop the redundant reverse columns
merged.drop(columns=[f"{col}_reverse" for col in ['Week', 'Visitor', 'VisitorScore', 'Home', 'HomeScore', 'OT']], inplace=True)

# Add binary target column: 1 if Home team won, 0 otherwise
merged['HomeWon'] = merged['HomeScore'] > merged['VisitorScore']

# Preview merged dataset
merged[['Date', 'Home', 'Visitor', 'HomeScore', 'VisitorScore', 'HomeWon']].head(50)

"""Team Feature Extraction"""

# Feature engineering: basic scoring and win rate metrics

# Load schedule for upcoming games (Week 1 of 2025 season)
upcoming_games = pd.read_csv(UPCOMING_FILE)

# Preview the upcoming schedule to verify the structure
print(upcoming_games.head(16))

# --- Average Points Scored ---

# Calculate average points scored at home and away
avg_scored_home = merged['HomeScore'].groupby(merged['Home']).mean()
avg_scored_away = merged['VisitorScore'].groupby(merged['Visitor']).mean()

# Combine to get total average points scored per team
avg_points_scored = (avg_scored_home + avg_scored_away) / 2

# --- Average Points Allowed ---

# Calculate average points allowed at home and away
avg_allowed_home = merged['VisitorScore'].groupby(merged['Home']).mean()
avg_allowed_away = merged['HomeScore'].groupby(merged['Visitor']).mean()

# Combine to get total average points allowed per team
avg_points_allowed = (avg_allowed_home + avg_allowed_away) / 2

# --- Win Rate ---

# Count wins as home and away
home_wins = merged.groupby('Home')['HomeWon'].sum()
away_wins = merged.groupby('Visitor')['HomeWon'].apply(lambda x: len(x) - x.sum())

# Count total games played as home and away
home_games = merged['Home'].value_counts()
away_games = merged['Visitor'].value_counts()

# Total wins and games played
total_wins = home_wins + away_wins
total_games = home_games + away_games

# Calculate overall win rate
win_rate = total_wins / total_games

# --- Assemble team-level features ---

# Combine all features into one DataFrame
team_features = pd.DataFrame({
    'AvgPointsScored': avg_points_scored,
    'AvgPointsAllowed': avg_points_allowed,
    'WinRate': win_rate
})

# Reset index and name the index column explicitly
team_features.reset_index(names='Team', inplace=True)

# Preview the engineered features
team_features.head(32)

# Feature engineering: defensive metrics (conceded plays and turnovers)

# --- Conceded Plays ---

# Define a successful offensive play as either a touchdown or a non-turnover play
merged['SuccessfulPlay'] = merged['IsTouchdown'] | (~merged['IsInterception'] & ~merged['IsFumble'])

# Calculate average rate of successful plays conceded at home and as a visitor
avg_conceded_home = merged.groupby('Home')['SuccessfulPlay'].mean()
avg_conceded_away = merged.groupby('Visitor')['SuccessfulPlay'].mean()

# Combine to get overall conceded play rate per team
avg_conceded_plays = (avg_conceded_home + avg_conceded_away) / 2

# --- Forced Turnovers ---

# Define a turnover as either an interception or a fumble
merged['Turnover'] = merged['IsInterception'] | merged['IsFumble']

# Calculate average forced turnovers at home and as a visitor
avg_turnovers_home = merged.groupby('Home')['Turnover'].mean()
avg_turnovers_away = merged.groupby('Visitor')['Turnover'].mean()

# Combine to get overall forced turnover rate per team
avg_forced_turnovers = (avg_turnovers_home + avg_turnovers_away) / 2

# --- Merge Defensive Features ---

# Create defensive metrics dataframe
team_features_def = pd.DataFrame({
    'Team': team_features['Team'],
    'AvgPointsDefended': team_features['AvgPointsAllowed'],  # Already calculated earlier
    'AvgConcededPlays': avg_conceded_plays.values,
    'AvgForcedTurnovers': avg_forced_turnovers.values
})

# Join defensive features into existing feature set
team_features_combined = team_features.merge(team_features_def, on='Team', how='left')

# Preview combined features
team_features_combined.head(32)

# Feature engineering: additional offensive metrics

# --- Average Yards Per Play ---

# Calculate mean yards gained per play at home and away
avg_yards_home = merged.groupby('Home')['Yards'].mean()
avg_yards_away = merged.groupby('Visitor')['Yards'].mean()

# Combine for team-wide average
avg_yards_per_play = (avg_yards_home + avg_yards_away) / 2

# --- Average Yards Per Game ---

# Sum total yards per team per season and divide by number of games played
total_yards_home = merged.groupby(['SeasonYear', 'Home'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Home']).size()
total_yards_away = merged.groupby(['SeasonYear', 'Visitor'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()

# Combine to get team-wide season average
avg_yards_per_game = (total_yards_home + total_yards_away).groupby(level=1).mean()

# --- Pass Completion Rate ---

# Completion rate = 1 - incompletion rate
pass_comp_home = merged.groupby('Home')['IsIncomplete'].mean().apply(lambda x: 1 - x)
pass_comp_away = merged.groupby('Visitor')['IsIncomplete'].mean().apply(lambda x: 1 - x)

# Combine to get overall pass completion rate
avg_pass_completion = (pass_comp_home + pass_comp_away) / 2

# --- Touchdowns Per Game ---

# Touchdowns per game = total TDs divided by games played (per season)
tds_home = merged.groupby(['SeasonYear', 'Home'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Home']).size()
tds_away = merged.groupby(['SeasonYear', 'Visitor'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()

# Combine for average TDs per game per team
avg_td_per_game = (tds_home + tds_away).groupby(level=1).mean()

# --- Rush Success Rate ---

# Rush success = average yards per rush
rush_success_home = merged[merged['IsRush'] == 1].groupby('Home')['Yards'].mean()
rush_success_away = merged[merged['IsRush'] == 1].groupby('Visitor')['Yards'].mean()

# Combine for team-wide average
avg_rush_success = (rush_success_home + rush_success_away) / 2

# --- Combine and Merge Offensive Features ---

# Create DataFrame of offensive metrics
offensive_features = pd.DataFrame({
    'Team': team_features_combined['Team'],
    'AvgYardsPerPlay': avg_yards_per_play.values,
    'AvgYardsPerGame': avg_yards_per_game.values,
    'AvgPassCompletionRate': avg_pass_completion.values,
    'AvgTouchdownsPerGame': avg_td_per_game.values,
    'AvgRushSuccessRate': avg_rush_success.values
})

# Merge into existing team feature set
team_features_expanded = team_features_combined.merge(offensive_features, on='Team')

# Preview final offensive features
team_features_expanded.head(32)

# Feature engineering: additional defensive metrics

# --- Yards Allowed Per Play ---

# Calculate average yards allowed per play at home and away
yards_allowed_home = merged.groupby('Home')['Yards'].mean()
yards_allowed_away = merged.groupby('Visitor')['Yards'].mean()

# Combine to get total average yards allowed per team
avg_yards_allowed = (yards_allowed_home + yards_allowed_away) / 2

# --- Total Yards Allowed Per Game ---

# Sum total yards allowed per season and divide by number of games
total_yards_home = merged.groupby(['SeasonYear', 'Home'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Home']).size()
total_yards_away = merged.groupby(['SeasonYear', 'Visitor'])['Yards'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()

# Combine and average over both sides
avg_yards_allowed_per_game = (total_yards_home + total_yards_away).groupby(level=1).mean()

# --- Pass Completion Allowed Rate ---

# Completion rate allowed = 1 - incompletion rate
comp_allowed_home = merged.groupby('Home')['IsIncomplete'].mean().apply(lambda x: 1 - x)
comp_allowed_away = merged.groupby('Visitor')['IsIncomplete'].mean().apply(lambda x: 1 - x)

# Combine for overall allowed completion rate
avg_pass_completion_allowed = (comp_allowed_home + comp_allowed_away) / 2

# --- Touchdowns Allowed Per Game ---

# Calculate touchdowns allowed per game from both sides
tds_allowed_home = merged.groupby(['SeasonYear', 'Home'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Home']).size()
tds_allowed_away = merged.groupby(['SeasonYear', 'Visitor'])['IsTouchdown'].sum() / merged.groupby(['SeasonYear', 'Visitor']).size()

# Combine and average
avg_tds_allowed_per_game = (tds_allowed_home + tds_allowed_away).groupby(level=1).mean()

# --- Rush Success Allowed Rate ---

# Calculate average yards per rush allowed at home and away
rush_allowed_home = merged[merged['IsRush'] == 1].groupby('Home')['Yards'].mean()
rush_allowed_away = merged[merged['IsRush'] == 1].groupby('Visitor')['Yards'].mean()

# Combine for overall rush success rate allowed
avg_rush_success_allowed = (rush_allowed_home + rush_allowed_away) / 2

# --- Combine and Merge Defensive Features ---

# Create DataFrame of defensive metrics
defensive_features = pd.DataFrame({
    'Team': team_features_expanded['Team'],
    'AvgYardsAllowedPerPlay': avg_yards_allowed.values,
    'AvgYardsAllowedPerGame': avg_yards_allowed_per_game.values,
    'AvgPassCompletionAllowedRate': avg_pass_completion_allowed.values,
    'AvgTouchdownsAllowedPerGame': avg_tds_allowed_per_game.values,
    'AvgRushSuccessAllowedRate': avg_rush_success_allowed.values
})

# Merge with the previous feature set
team_features_complete = team_features_expanded.merge(defensive_features, on='Team')

# Preview the completed team feature dataset
team_features_complete.head(32)

# Game-level feature encoding for upcoming Week 1 matchups

# Reload upcoming games (redundant in Colab, but ensures fresh read if needed)
upcoming_games = pd.read_csv(UPCOMING_FILE)

# Merge home team features
upcoming_merged = upcoming_games.merge(
    team_features_complete,
    left_on='Home',
    right_on='Team',
    how='left'
)

# Merge visitor team features and suffix columns appropriately
upcoming_merged = upcoming_merged.merge(
    team_features_complete,
    left_on='Visitor',
    right_on='Team',
    how='left',
    suffixes=('_Home', '_Visitor')
)

# Preview encoded game matrix
upcoming_merged.head(16)

"""Data Training Preparation"""

# Training set construction: join game data with team features and build home-vs-visitor deltas

# Merge team features for the home side
training_encoded_home = merged.merge(
    team_features_complete,
    left_on='Home',
    right_on='Team',
    how='left'
)

# Merge team features for the visitor side (suffixes disambiguate feature columns)
training_encoded_both = training_encoded_home.merge(
    team_features_complete,
    left_on='Visitor',
    right_on='Team',
    how='left',
    suffixes=('_Home', '_Visitor')
)

# List the team-level feature names to difference (explicit for reproducibility)
diff_source_cols = [
    'AvgPointsScored', 'AvgPointsAllowed', 'WinRate',
    'AvgPointsDefended', 'AvgConcededPlays', 'AvgForcedTurnovers',
    'AvgYardsPerPlay', 'AvgYardsPerGame', 'AvgPassCompletionRate',
    'AvgTouchdownsPerGame', 'AvgRushSuccessRate',
    'AvgYardsAllowedPerPlay', 'AvgYardsAllowedPerGame',
    'AvgPassCompletionAllowedRate', 'AvgTouchdownsAllowedPerGame',
    'AvgRushSuccessAllowedRate'
]

# Create home-minus-visitor differences for each feature
for col in diff_source_cols:
    training_encoded_both[f'Diff_{col}'] = (
        training_encoded_both[f'{col}_Home'] - training_encoded_both[f'{col}_Visitor']
    )

# Select model inputs (all Diff_ columns) and the target (home team win flag)
training_data = training_encoded_both[[c for c in training_encoded_both.columns if c.startswith('Diff_')]]
training_labels = training_encoded_both['HomeWon']

# Preview a sample of the finalized training matrix
training_data.head(50)

# Sanity checks: verify training matrix and labels before modeling

# Basic shapes
print("training_data shape:", training_data.shape)
print("training_labels shape:", training_labels.shape)

# Index alignment (ensures each row of X maps to the same row of y)
aligned = training_data.index.equals(training_labels.index)
print("Index aligned:", aligned)

# Missing values
total_feature_nas = int(training_data.isna().sum().sum())
label_nas = int(training_labels.isna().sum())
print("Total missing values in training_data:", total_feature_nas)
print("Missing labels:", label_nas)

# Type check: ensure all features are numeric
non_numeric_cols = training_data.select_dtypes(exclude=[np.number]).columns.tolist()
print("Non-numeric feature columns:", non_numeric_cols if non_numeric_cols else "None")

# Label distribution (helps catch class imbalance issues)
print("\nLabel distribution (HomeWon):")
print(training_labels.value_counts(dropna=False))

# Preview: show a small sample of the feature matrix
print("\nFeature columns (first 10):", list(training_data.columns[:10]))
training_data.head(10)

"""AI Model Training"""

# Model evaluation: logistic regression with k-fold cross-validation (no training changes)

# Imports repeated locally so this cell can run independently if needed
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# Initialize the baseline logistic regression model
# Note: This is intentionally unchanged to keep parity with the original behavior
logreg = LogisticRegression(max_iter=1000)

# Evaluate the model using k-fold cross-validation
# Returns an array of scores (one per fold)
cross_val_scores = cross_val_score(
    estimator=logreg,
    X=training_data,
    y=training_labels,
    cv=10
)

# Compute the mean cross-validated score for quick comparison later
cross_val_scores_mean = cross_val_scores.mean()

# Display the mean CV score
cross_val_scores_mean

# Model training: fit logistic regression on the full training dataset (unchanged behavior)

# Fit the model on all available training data after cross-validation
logreg.fit(training_data, training_labels)

# Optional: lightweight confirmation for visibility during refactors
print("Model fitted. Coefficients shape:", getattr(logreg, "coef_", None).shape if hasattr(logreg, "coef_") else None)

"""Upcoming Game Predictions"""

# Upcoming games: construct home-minus-visitor feature deltas for Week 1 predictions

# Copy to avoid mutating the merged base
upcoming_features = upcoming_merged.copy()

# Use the same feature list used for training to avoid column drift
feature_cols = [f"Diff_{c}" for c in diff_source_cols]

# Create difference columns for each team-level feature
for col in diff_source_cols:
    home_col = f"{col}_Home"
    away_col = f"{col}_Visitor"
    diff_col = f"Diff_{col}"
    if home_col not in upcoming_features.columns or away_col not in upcoming_features.columns:
        raise KeyError(f"Required columns missing for upcoming games: '{home_col}' or '{away_col}'")
    upcoming_features[diff_col] = upcoming_features[home_col] - upcoming_features[away_col]

# Slice the finalized model input matrix for upcoming games
upcoming_X = upcoming_features[feature_cols].copy()

# Quick sanity checks before inference
print("Upcoming_X shape:", upcoming_X.shape)
print("Total missing values in upcoming_X:", int(upcoming_X.isna().sum().sum()))

# If there are NaNs, print which rows are affected to make debugging easier
if upcoming_X.isna().any().any():
    bad_rows = upcoming_X.index[upcoming_X.isna().any(axis=1)].tolist()
    print("Rows with missing values in upcoming_X:", bad_rows)

# Inference: predict home-win probabilities for upcoming games and present results

# Predict probability that the home team wins (class 1)
upcoming_proba = logreg.predict_proba(upcoming_X)[:, 1]

# Attach predictions to the upcoming_features table
results = upcoming_features.copy()
results['Home Win Probability'] = upcoming_proba

# Determine predicted winner (threshold = 0.5 to match current model behavior)
results['Predicted Winner'] = results.apply(
    lambda r: r['Home'] if r['Home Win Probability'] >= 0.5 else r['Visitor'],
    axis=1
)

# Select a clean view for presentation
presentation_cols = ['Home', 'Visitor', 'Home Win Probability', 'Predicted Winner']
if 'Week' in results.columns:
    presentation_cols = ['Week'] + presentation_cols

# Sort by confidence in the home team (descending)
upcoming_predictions = results[presentation_cols].sort_values(by='Home Win Probability', ascending=False)

# Preview final predictions
upcoming_predictions